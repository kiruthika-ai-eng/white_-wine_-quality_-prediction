# ü•Ç White Wine Quality Prediction

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)
![Machine Learning](https://img.shields.io/badge/Machine%20Learning-Random%20Forest-orange)
![Deep Learning](https://img.shields.io/badge/Deep%20Learning-TensorFlow%2FKeras-red)
![License](https://img.shields.io/badge/License-MIT-green)

---

## üìò Overview
> ‚ÄúWine is the most healthful and most hygienic of beverages.‚Äù ‚Äì *Louis Pasteur*  

This is an **end-to-end Machine Learning and Deep Learning project** that analyzes and predicts the **quality of white wine** based on its **physicochemical properties**.  
The project uses both **Random Forest Classification** and **Deep Neural Network (DNN) Regression** models to evaluate and predict wine quality scores.

---

## üìä Dataset
**Source:** [Kaggle - Wine Quality Red & White Dataset](https://www.kaggle.com/datasets/abdullah0a/wine-quality-red-white-analysis-dataset)

### Features (Input Variables)
| Feature | Description |
|----------|--------------|
| Fixed Acidity | Tartaric, succinic, citric, and malic acids |
| Volatile Acidity | Gaseous acids present in wine |
| Citric Acid | Weak organic acid, adds freshness |
| Residual Sugar | Sugar remaining after fermentation |
| Chlorides | Amount of salt present |
| Free SO‚ÇÇ | Protects wine from oxidation & microbes |
| Total SO‚ÇÇ | Combined free + bound sulfur dioxide |
| Density | Density of wine |
| pH | Acidity level |
| Sulphates | Adds preservatives and flavor |
| Alcohol | Percentage of alcohol |
| **Quality** | Target variable (score between 0‚Äì10) |

---
‚öôÔ∏è Tech Stack
- **Languages:** Python  
- **Libraries:** Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, TensorFlow, Keras  
- **Environment:** Google Colab  

---

## üß† Machine Learning Approach

### 1Ô∏è‚É£ Data Preprocessing
- Checked for missing values (`isnull().sum()`)
- Descriptive statistics using `describe()` and `info()`
- Label binarization:  
  - Quality ‚â• 7 ‚Üí **Good (1)**  
  - Quality < 7 ‚Üí **Not Good (0)**  
- Split data: 80% Training / 20% Testing

### 2Ô∏è‚É£ Visualization
- Count plots for quality distribution  
- Correlation heatmap between features  
- Feature relationships with wine quality  

### 3Ô∏è‚É£ Model Training ‚Äì **Random Forest Classifier**
- Built and trained using Scikit-learn  
- Achieved **Accuracy: 87.75%**  
- Model generalized well without overfitting  

### 4Ô∏è‚É£ Predictive System
- Takes physicochemical inputs (from dataset or user)
- Outputs **‚ÄúGood‚Äù** or **‚ÄúBad‚Äù** wine quality prediction

---

## ü§ñ Deep Learning Approach

### 1Ô∏è‚É£ Model Architecture
- **Input Layer:** 11 features  
- **Hidden Layers:** 3 layers √ó 512 neurons, ReLU activation  
- **Output Layer:** 1 neuron (continuous output)  

### 2Ô∏è‚É£ Training Setup
- Normalized data using `StandardScaler`
- Optimizer: **Adam**  
- Loss Function: **Mean Absolute Error (MAE)**  
- Batch Size: 256 | Epochs: 10‚Äì100  

### 3Ô∏è‚É£ Enhancements
- Implemented **Early Stopping** to prevent overfitting  
- Added **Dropout (0.3)** and **Batch Normalization** for stability  
- Used validation set to monitor performance  

### 4Ô∏è‚É£ Results
| Model | Metric | Result | Remarks |
| Random Forest | Accuracy | **87.75%** | Strong baseline |
| DNN Regression | MAE | **0.10** | Excellent precision |

---

## üìà Results & Insights
- **Random Forest**: Quick, interpretable, and effective classification  
- **DNN Regression**: Captured complex nonlinear patterns for continuous prediction  
- Combining ML & DL shows how hybrid approaches can provide both interpretability and high performance.

---

## üìÇ Project Structure
```
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ winequality-white.csv
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ white_wine_quality.ipynb
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ random_forest.pkl
‚îÇ   ‚îî‚îÄ‚îÄ dnn_model.h5
‚îú‚îÄ‚îÄ visuals/
‚îÇ   ‚îú‚îÄ‚îÄ correlation_heatmap.png
‚îÇ   ‚îî‚îÄ‚îÄ loss_curve.png
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt
```

---

## üöÄ How to Run
1. Clone this repository:
   ```bash
   git clone https://github.com/kiruthika-ai-eng/white-wine-quality-prediction.git
   cd white-wine-quality-prediction
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Open the notebook:
   ```bash
   Google collab notebooks/white_wine_quality.ipynb
   ```
4. Run all cells to reproduce results.

---

## üèÜ Key Learnings
- Data preprocessing and feature scaling significantly affect model performance.  
- Random Forests are strong baselines for tabular data.  
- Deep Learning (DNN) can capture nonlinear relationships if tuned properly.  
- Early stopping and dropout help avoid overfitting.

---

## üë©‚Äçüíª Author
**Developed by:** [kiruthika-ai-eng](https://github.com/kiruthika-ai-eng)  

If you like this project, please ‚≠ê it on GitHub ‚Äî it really helps!

---

## üìú License
This project is licensed under the **MIT License** ‚Äî feel free to use, modify, and share.
